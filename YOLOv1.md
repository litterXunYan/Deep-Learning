#YOLOv1论文阅读笔记

##整体思路
用YOLO处理图像是简单明了的。我们的系统分如下三个步骤
(1)将输入图像的大小调整为448×448；
(2)在图像上运行单个卷积网络；
(3)根据模型的置信度对得到的检测进行阈值化。

yolov1的输入图像为固定大小：448*448；网络是从整个图像着手，去预测bbox；
将图像分成s*s网格区域，当物体的中心落在某一个网格中时，该网格就负责检测该物体，并且一个网格只负责检测一个物体，
论文总S = 7，每个网格中预测两个bbox，bbox的参数形式为(x, y, w, h, p),其中p为Pr(object)*IOU,这里需要注意的是：
虽然有两个bbox，但是在计算梯度以及反向传播的时候只有IOU最大的那个参与运算；
换句话说：若bounding box包含物体，则P(object) = 1；否则P(object) = 0。IOU(intersection over union)为预测bounding
box与物体真实区域的交集面积（以像素为单位，用真实区域的像素面积归一化到[0,1]区间）。
S*S*(B*5+C)

注意：
1.实际训练过程中，w和h的值使用图像的宽度和高度进行归一化到[0,1]区间内；x，y是bounding box中心位置相对于当前格子位置的偏移值，并且被归一化到[0,1]。
2.由于输出层为全连接层，因此在检测时，YOLO训练模型只支持与训练图像相同的输入分辨率。
3.虽然每个格子可以预测B个bounding box，但是最终只选择只选择IOU最高的bounding box作为物体检测输出，即每个格子最多只预测出一个物体。
当物体占画面比例较小，如图像中包含畜群或鸟群时，每个格子包含多个物体，但却只能检测出其中一个。这是YOLO方法的一个缺陷。
4.class的信息是针对每个网格的，confidence信息是针对每个bbox的

##网络结构
YOLO网络结构借鉴了 GoogLeNet 。YOLO检测网络包括24个卷积层和2个全连接层
卷积层用来提取图像特征，全连接层用来预测图像位置和类别概率值。YOLO网络借鉴了GoogLeNet分类网络结构。不同的是，
YOLO未使用inception module，而是使用1x1卷积层（此处1x1卷积层的存在是为了跨通道信息整合）+3x3卷积层简单替代。最终输出的是7x7x30的张量的预测值。


##训练
预训练分类网络： 在 ImageNet 1000-class competition dataset上预训练一个分类网络，这个网络是网络结构中的前20个卷机网络
+average-pooling layer（平均池化层）+ fully connected layer（全连接层） （此时网络输入是224*224）。
训练检测网络：在上述基础上添加4个卷积层和2个全链接层，随机初始化权重。检测要求细粒度的视觉信息，所以把网络输入把224*224变成448*448。
最后一层网络使用线性激活函数，其它网络层都是用leaky_relu函数，系数为0.1；


##损失函数
训练135epochs，第一个eopch中lr从0.0001逐步上升到0.001，使用0.001的lr训练75个eopchs，接着使用0.0001的lr训练30epochs，再使用0.00001的lr训练20epochs
为了避免过拟合，在第一个全连接层后面添加了dropout层，rate=0.5

![image]()
